{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae3df1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e281f",
   "metadata": {},
   "source": [
    "## Overlap patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c98df1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('overlap_input_image.png')\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e380b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "# h, w, in_channels = img.shape\n",
    "\n",
    "# stride = 80\n",
    "# patch_size = 128 \n",
    "# out_channels = in_channels\n",
    "\n",
    "\n",
    "# def outsize(dim, k, s, p):\n",
    "#     return int((dim - k + 2*p) / s) + 1\n",
    "\n",
    "# row_iter = outsize(h, patch_size, stride, 0)\n",
    "# col_iter = outsize(w, patch_size, stride, 0)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(row_iter, col_iter, figsize=(10,10))\n",
    "\n",
    "# for i in range(row_iter):\n",
    "#     for j in range(col_iter):\n",
    "#         start_row = i * stride\n",
    "#         end_row = start_row + patch_size\n",
    "#         start_col = j * stride\n",
    "#         end_col = start_col + patch_size\n",
    "        \n",
    "#         axes[i][j].imshow(img[start_row : end_row, start_col : end_col, :])\n",
    "#         axes[i][j].axis('off')\n",
    "#         axes[i][j].set_xticklabels([])\n",
    "#         axes[i][j].set_yticklabels([])        \n",
    "\n",
    "# # set the spacing between subplots\n",
    "# fig.tight_layout()\n",
    "# # plt.subplots_adjust(wspace=0.05, hspace=0.05)        \n",
    "# plt.show()\n",
    "# fig.savefig('temp.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25dab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ffb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ea0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc734859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c297696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('anibali/segformer', 'segformer_b2', pretrained=True, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.Tensor(1,3, 360, 640)\n",
    "# output = model(input)\n",
    "# output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(imgseg)",
   "language": "python",
   "name": "imgseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
