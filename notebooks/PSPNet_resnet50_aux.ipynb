{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkfoFeGlYxHY"
   },
   "source": [
    "## Welcome to the `PSPNet` Workshop!\n",
    "In this workshop, we'll learn the concept of how to use PSPNet (Pyramid Scene Parsing Network) for Semantic Segmentation using Pytorch. We'll do the following tasks:\n",
    "\n",
    "- Dataset : Download and use BDD100k dataset\n",
    "- Network : Define PSPNet model using resnet50 Pyramid Pooling Module architecture and Auxilary loss\n",
    "- Training : Train and validate model on the custom dataset\n",
    "- Evaluate : Evaluate the model on Test Data and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:43.029996Z",
     "iopub.status.busy": "2022-06-26T09:17:43.029186Z",
     "iopub.status.idle": "2022-06-26T09:17:47.009185Z",
     "shell.execute_reply": "2022-06-26T09:17:47.007785Z",
     "shell.execute_reply.started": "2022-06-26T09:17:43.029892Z"
    },
    "id": "-njz3v-jGxsi",
    "outputId": "77838d12-01f5-4ab1-d1d8-8bbe08bf2cc1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except:\n",
    "    !pip install segmentation-models-pytorch\n",
    "    import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKDStTzOQ_3R"
   },
   "source": [
    "# Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.012097Z",
     "iopub.status.busy": "2022-06-26T09:17:47.011377Z",
     "iopub.status.idle": "2022-06-26T09:17:47.042399Z",
     "shell.execute_reply": "2022-06-26T09:17:47.041415Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.012036Z"
    },
    "id": "-73t7omkQ-y7"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# DL library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# libraries for loading image, plotting \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G6V9TIjsZB7"
   },
   "source": [
    "# 1. Dataset : Download and use BDD100k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.044226Z",
     "iopub.status.busy": "2022-06-26T09:17:47.043691Z",
     "iopub.status.idle": "2022-06-26T09:17:47.050819Z",
     "shell.execute_reply": "2022-06-26T09:17:47.049543Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.044186Z"
    }
   },
   "outputs": [],
   "source": [
    "ENVIRONMENT = 'kaggle'\n",
    "\n",
    "if ENVIRONMENT == 'kaggle':\n",
    "    dataset_path = '../input/image-segmentation'\n",
    "    output_path = '.'\n",
    "    \n",
    "elif ENVIRONMENT == 'colab':\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    os.chdir(\"/content/drive/My Drive/thinkAutonomous/image_segmentation\")\n",
    "    dataset_path = 'dataset'\n",
    "    output_path = 'dataset'\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(\"Env can be kaggle or colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.054386Z",
     "iopub.status.busy": "2022-06-26T09:17:47.053966Z",
     "iopub.status.idle": "2022-06-26T09:17:47.061852Z",
     "shell.execute_reply": "2022-06-26T09:17:47.060970Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.054350Z"
    },
    "id": "adLoblQrpzzy",
    "outputId": "695af3d8-f020-4f37-9734-dcf9f0163229"
   },
   "outputs": [],
   "source": [
    "targetWidth = 320\n",
    "targetHeight = 180\n",
    "\n",
    "# batch size for data loaders\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE  = 8\n",
    "\n",
    "# Hyperparameters\n",
    "N_EPOCHS = 10\n",
    "NUM_CLASSES = 3\n",
    "MAX_LR = 3e-4\n",
    "MODEL_NAME = 'PSPNet_resnet50_aux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.063968Z",
     "iopub.status.busy": "2022-06-26T09:17:47.063576Z",
     "iopub.status.idle": "2022-06-26T09:17:47.337272Z",
     "shell.execute_reply": "2022-06-26T09:17:47.336064Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.063933Z"
    }
   },
   "outputs": [],
   "source": [
    "images = np.load(f'{dataset_path}/image_{targetHeight}_{targetWidth}.npy')\n",
    "labels = np.load(f'{dataset_path}/label_{targetHeight}_{targetWidth}.npy')\n",
    "print(f\"RGB images shape = {images.shape}, Label images shape = {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmFiD3i-0Crd"
   },
   "source": [
    "## Torch Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.339395Z",
     "iopub.status.busy": "2022-06-26T09:17:47.338970Z",
     "iopub.status.idle": "2022-06-26T09:17:47.347776Z",
     "shell.execute_reply": "2022-06-26T09:17:47.346181Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.339353Z"
    },
    "id": "ySpXTOvpmPk8"
   },
   "outputs": [],
   "source": [
    "class BDD100k_dataset(Dataset):\n",
    "    def __init__(self, images, labels, tf=None):\n",
    "        \"\"\"Dataset class for BDD100k_dataset drivable / segmentation data \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.tf = tf\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # read source image and convert to RGB, apply transform\n",
    "        rgb_image = self.images[index]\n",
    "        if self.tf is not None:\n",
    "            rgb_image = self.tf(rgb_image)\n",
    "\n",
    "        # read label image and convert to torch tensor\n",
    "        label_image  = torch.from_numpy(self.labels[index]).long()\n",
    "        return rgb_image, label_image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.350493Z",
     "iopub.status.busy": "2022-06-26T09:17:47.350047Z",
     "iopub.status.idle": "2022-06-26T09:17:47.359499Z",
     "shell.execute_reply": "2022-06-26T09:17:47.358584Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.350455Z"
    },
    "id": "r6XW6HajnzPq"
   },
   "outputs": [],
   "source": [
    "# Convert to torch tensor and normalize images using Imagenet values\n",
    "preprocess = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.56, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data = BDD100k_dataset(images, labels, tf=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB9JLxjfoENJ"
   },
   "source": [
    "Splitting Training data into train and validation sets, creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.362845Z",
     "iopub.status.busy": "2022-06-26T09:17:47.362029Z",
     "iopub.status.idle": "2022-06-26T09:17:47.370445Z",
     "shell.execute_reply": "2022-06-26T09:17:47.369506Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.362807Z"
    },
    "id": "KKXj9c2qoC40"
   },
   "outputs": [],
   "source": [
    "# split train data into train, validation and test sets\n",
    "total_count = len(data)\n",
    "train_count = int(0.7 * total_count) \n",
    "valid_count = int(0.2 * total_count)\n",
    "test_count = total_count - train_count - valid_count\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(data, \n",
    "            (train_count, valid_count, test_count), generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE,drop_last=True)\n",
    "val_dataloader   = DataLoader(val_set, batch_size=TEST_BATCH_SIZE)\n",
    "test_dataloader  = DataLoader(test_set, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku1BYOyXosMD"
   },
   "source": [
    "Let's verify size of images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.372635Z",
     "iopub.status.busy": "2022-06-26T09:17:47.372198Z",
     "iopub.status.idle": "2022-06-26T09:17:47.384580Z",
     "shell.execute_reply": "2022-06-26T09:17:47.383235Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.372601Z"
    },
    "id": "yWrMEcQQota2",
    "outputId": "088865c6-546f-4b68-a0b0-4a35a99d03f9"
   },
   "outputs": [],
   "source": [
    "sample_image, sample_label = train_set[0]\n",
    "print(f\"There are {len(train_set)} train images, {len(val_set)} validation images, {len(test_set)} test Images\")\n",
    "print(f\"Input shape = {sample_image.shape}, output label shape = {sample_label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhMFn7YWprGr"
   },
   "source": [
    "## Show Sample images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.388979Z",
     "iopub.status.busy": "2022-06-26T09:17:47.388730Z",
     "iopub.status.idle": "2022-06-26T09:17:47.395840Z",
     "shell.execute_reply": "2022-06-26T09:17:47.394702Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.388956Z"
    },
    "id": "jOQpj7kfq_tM"
   },
   "outputs": [],
   "source": [
    "# reference : https://github.com/bdd100k/bdd100k/blob/master/bdd100k/label/label.py\n",
    "from collections import namedtuple\n",
    "Label = namedtuple( \"Label\", [ \"name\", \"train_id\", \"color\"])\n",
    "drivables = [ \n",
    "             Label(\"direct\", 0, (219, 94, 86)),        # red\n",
    "             Label(\"alternative\", 1, (86, 211, 219)),  # cyan\n",
    "             Label(\"background\", 2, (0, 0, 0)),        # black          \n",
    "            ]\n",
    "train_id_to_color = [c.color for c in drivables if (c.train_id != -1 and c.train_id != 255)]\n",
    "train_id_to_color = np.array(train_id_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.398955Z",
     "iopub.status.busy": "2022-06-26T09:17:47.398074Z",
     "iopub.status.idle": "2022-06-26T09:17:47.714533Z",
     "shell.execute_reply": "2022-06-26T09:17:47.712946Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.398913Z"
    },
    "id": "UneBdP1LvZQr",
    "outputId": "cf00c661-2725-4604-bc6c-ce4a72f11139"
   },
   "outputs": [],
   "source": [
    "# when using torch datasets we defined earlier, the output image\n",
    "# is normalized. So we're defining an inverse transformation to \n",
    "# transform to normal RGB format\n",
    "inverse_transform = transforms.Compose([\n",
    "        transforms.Normalize((-0.485/0.229, -0.456/0.224, -0.406/0.225), (1/0.229, 1/0.224, 1/0.225))\n",
    "    ])\n",
    "\n",
    "rgb_image, label = train_set[random.randint(0, len(train_set))]\n",
    "rgb_image = inverse_transform(rgb_image).permute(1, 2, 0).cpu().detach().numpy()\n",
    "label = label.cpu().detach().numpy()\n",
    "\n",
    "# plot sample image\n",
    "fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "axes[0].imshow(rgb_image);\n",
    "axes[0].set_title(\"Image\");\n",
    "axes[0].axis('off');\n",
    "axes[1].imshow(train_id_to_color[label]);\n",
    "axes[1].set_title(\"Label\");\n",
    "axes[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbOYP8UHc8s3"
   },
   "source": [
    "# Network : Define PSPNet model using resnet50 Pyramid Pooling Module architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.715906Z",
     "iopub.status.busy": "2022-06-26T09:17:47.715595Z",
     "iopub.status.idle": "2022-06-26T09:17:47.738199Z",
     "shell.execute_reply": "2022-06-26T09:17:47.737119Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.715876Z"
    }
   },
   "outputs": [],
   "source": [
    "class pyramid_pooling_module(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bin_sizes):\n",
    "        super(pyramid_pooling_module, self).__init__()\n",
    "        \n",
    "        # create pyramid pooling layers for each level\n",
    "        self.pyramid_pool_layers = []\n",
    "        for bin_sz in bin_sizes:\n",
    "            self.pyramid_pool_layers.append(nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(bin_sz),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.pyramid_pool_layers = nn.ModuleList(self.pyramid_pool_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        out = [x]\n",
    "        for layer in self.pyramid_pool_layers:\n",
    "            out.append(F.interpolate(layer(x), x_size[2:], mode='bilinear', align_corners=True))\n",
    "        return torch.cat(out, 1)\n",
    "    \n",
    "\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, use_aux=False):\n",
    "        super(PSPNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "                \n",
    "        # backbone layers\n",
    "        backbone = resnet50(pretrained=True, replace_stride_with_dilation=[False, True, True])        \n",
    "        self.initial = nn.Sequential(*list(backbone.children())[:4])\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "        \n",
    "        # Pyramid pooling module components\n",
    "        ppm_in_channels = int(backbone.fc.in_features)\n",
    "        self.ppm = pyramid_pooling_module(in_channels=ppm_in_channels, \n",
    "                                     out_channels=512, bin_sizes=[1,2,3,6])\n",
    "        \n",
    "        # classifier head\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Conv2d(ppm_in_channels * 2, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.1),\n",
    "            nn.Conv2d(512,  self.num_classes, kernel_size=1)            \n",
    "        )\n",
    "        \n",
    "        # main branch is composed of PPM + Classifier\n",
    "        self.main_branch = nn.Sequential(self.ppm, self.cls)\n",
    "        \n",
    "        # Define Auxilary branch if specified\n",
    "        self.use_aux = False\n",
    "        if(self.training and use_aux):\n",
    "            self.use_aux = True\n",
    "            self.aux_branch = nn.Sequential(\n",
    "                nn.Conv2d( int(ppm_in_channels / 2) , 256, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(p=0.1),\n",
    "                nn.Conv2d(256, self.num_classes, kernel_size=1)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[-2:]\n",
    "        \n",
    "        # Pass input through Backbone layers\n",
    "        x = self.initial(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x_aux = self.layer3(x)\n",
    "        x = self.layer4(x_aux)\n",
    "        \n",
    "        # Get Main branch output\n",
    "        main_output = self.main_branch(x)\n",
    "        main_output = F.interpolate(main_output, size=input_size, mode='bilinear')\n",
    "        \n",
    "        # If needed, get auxiliary branch output\n",
    "        if(self.training and self.use_aux):\n",
    "            aux_output = F.interpolate(self.aux_branch(x_aux), size=input_size, mode='bilinear')\n",
    "            output = {}\n",
    "            output['aux'] = aux_output\n",
    "            output['main'] = main_output\n",
    "            return output\n",
    "        \n",
    "        return main_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeI63CaFc8s6"
   },
   "source": [
    "# 3. Training : Train and validate model on the custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hBQ5Xmuc8s7"
   },
   "source": [
    "\n",
    "Before we train our model, we'll define some helper functions to calculate metric, plot training results etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2saoCUQc8s8"
   },
   "source": [
    "## Metric - meanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.740198Z",
     "iopub.status.busy": "2022-06-26T09:17:47.739818Z",
     "iopub.status.idle": "2022-06-26T09:17:47.753001Z",
     "shell.execute_reply": "2022-06-26T09:17:47.751927Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.740160Z"
    },
    "id": "MRyngm4nc8s8"
   },
   "outputs": [],
   "source": [
    "class meanIoU:\n",
    "    \"\"\" Class to find the mean IoU using confusion matrix approach \"\"\"    \n",
    "    def __init__(self, num_classes):\n",
    "        self.iou_metric = 0.0\n",
    "        self.num_classes = num_classes\n",
    "        # placeholder for confusion matrix on entire dataset\n",
    "        self.confusion_matrix = np.zeros((self.num_classes, self.num_classes))\n",
    "\n",
    "    def update(self, y_preds, labels):\n",
    "        \"\"\" Function finds the IoU for the input batch\n",
    "        and add batch metrics to overall metrics \"\"\"\n",
    "        predicted_labels = torch.argmax(y_preds, dim=1)\n",
    "        batch_confusion_matrix = self._fast_hist(labels.numpy().flatten(), predicted_labels.numpy().flatten())\n",
    "        self.confusion_matrix += batch_confusion_matrix\n",
    "    \n",
    "    def _fast_hist(self, label_true, label_pred):\n",
    "        \"\"\" Function to calculate confusion matrix on single batch \"\"\"\n",
    "        mask = (label_true >= 0) & (label_true < self.num_classes)\n",
    "        hist = np.bincount(\n",
    "            self.num_classes * label_true[mask].astype(int) + label_pred[mask],\n",
    "            minlength=self.num_classes ** 2,\n",
    "        ).reshape(self.num_classes, self.num_classes)\n",
    "        return hist\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\" Computes overall meanIoU metric from confusion matrix data \"\"\" \n",
    "        hist = self.confusion_matrix\n",
    "        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "        mean_iu = np.nanmean(iu)\n",
    "        return mean_iu\n",
    "\n",
    "    def reset(self):\n",
    "        self.iou_metric = 0.0\n",
    "        self.confusion_matrix = np.zeros((self.num_classes, self.num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZBAn9xXc8s9"
   },
   "source": [
    "## Function to plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.756350Z",
     "iopub.status.busy": "2022-06-26T09:17:47.755019Z",
     "iopub.status.idle": "2022-06-26T09:17:47.765968Z",
     "shell.execute_reply": "2022-06-26T09:17:47.765058Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.756314Z"
    },
    "id": "2Ft6-lRuc8s-"
   },
   "outputs": [],
   "source": [
    "def plot_training_results(df, model_name):\n",
    "    fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "    ax1.set_ylabel('trainLoss', color='tab:red')\n",
    "    ax1.plot(df['epoch'].values, df['trainLoss'].values, color='tab:red')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('validationLoss', color='tab:blue')\n",
    "    ax2.plot(df['epoch'].values, df['validationLoss'].values, color='tab:blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    plt.suptitle(f'{model_name} Training, Validation Curves')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye0G3dMEc8s-"
   },
   "source": [
    "## Train validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.770078Z",
     "iopub.status.busy": "2022-06-26T09:17:47.768217Z",
     "iopub.status.idle": "2022-06-26T09:17:47.780500Z",
     "shell.execute_reply": "2022-06-26T09:17:47.779529Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.770037Z"
    },
    "id": "rq5tJoYXc8s_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, metric_class, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric_object = metric_class(NUM_CLASSES)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, total=len(dataloader), position=0, leave=True):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)                \n",
    "            y_preds = model(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(y_preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # update batch metric information            \n",
    "            metric_object.update(y_preds.cpu().detach(), labels.cpu().detach())\n",
    "\n",
    "    evaluation_loss = total_loss / len(dataloader)\n",
    "    evaluation_metric = metric_object.compute()\n",
    "    return evaluation_loss, evaluation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.783970Z",
     "iopub.status.busy": "2022-06-26T09:17:47.783159Z",
     "iopub.status.idle": "2022-06-26T09:17:47.795966Z",
     "shell.execute_reply": "2022-06-26T09:17:47.795019Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.783932Z"
    },
    "id": "oSX6yKZQc8tA"
   },
   "outputs": [],
   "source": [
    "def train_validate_model(model, num_epochs, model_name, criterion, optimizer, \n",
    "                         device, dataloader_train, dataloader_valid, \n",
    "                         metric_class, metric_name, lr_scheduler = None):\n",
    "    # initialize placeholders for running values\n",
    "    results = []    \n",
    "    min_val_loss = np.Inf\n",
    "    len_train_loader = len(dataloader_train)\n",
    "\n",
    "    # move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting {epoch + 1} epoch ...\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in tqdm(dataloader_train, total=len_train_loader,position=0, leave=True):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "\n",
    "            # Forward pass\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            train_loss += loss.item()\n",
    "              \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # adjust learning rate\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step()\n",
    "            \n",
    "        # compute per batch losses, metric value\n",
    "        train_loss = train_loss / len(dataloader_train)\n",
    "        validation_loss, validation_metric = evaluate_model(\n",
    "                        model, dataloader_valid, criterion, metric_class, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, trainLoss:{train_loss:6.5f}, validationLoss:{validation_loss:6.5f}, {metric_name}:{validation_metric: 4.2f}')\n",
    "        \n",
    "        # store results\n",
    "        results.append({'epoch': epoch, \n",
    "                        'trainLoss': train_loss, \n",
    "                        'validationLoss': validation_loss, \n",
    "                        f'{metric_name}': validation_metric})\n",
    "        \n",
    "        # if validation loss has decreased, save model and reset variable\n",
    "        if validation_loss <= min_val_loss:\n",
    "            min_val_loss = validation_loss\n",
    "            torch.save(model.state_dict(), f\"{output_path}/{model_name}.pt\")\n",
    "\n",
    "    # plot results\n",
    "    results = pd.DataFrame(results)\n",
    "    plot_training_results(results, model_name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCnjwooT0Rde"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.798550Z",
     "iopub.status.busy": "2022-06-26T09:17:47.797764Z",
     "iopub.status.idle": "2022-06-26T09:17:47.807844Z",
     "shell.execute_reply": "2022-06-26T09:17:47.806865Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.798513Z"
    }
   },
   "outputs": [],
   "source": [
    "class pspnet_loss(nn.Module):\n",
    "    def __init__(self, aux_weight):\n",
    "        super(pspnet_loss, self).__init__()\n",
    "        self.loss_fn = smp.losses.DiceLoss('multiclass', classes=[0,1,2], log_loss = True, smooth=1.0)\n",
    "        self.aux_weight = aux_weight\n",
    "    \n",
    "    def forward(self, preds, labels):\n",
    "        if(isinstance(preds, dict) == True):\n",
    "            main_loss = self.loss_fn(preds['main'], labels)\n",
    "            aux_loss = self.loss_fn(preds['aux'], labels)\n",
    "            loss = (1 - self.aux_weight) * main_loss + self.aux_weight * aux_loss\n",
    "        else:\n",
    "            loss = self.loss_fn(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:17:47.810082Z",
     "iopub.status.busy": "2022-06-26T09:17:47.809325Z",
     "iopub.status.idle": "2022-06-26T09:23:50.476409Z",
     "shell.execute_reply": "2022-06-26T09:23:50.475234Z",
     "shell.execute_reply.started": "2022-06-26T09:17:47.810044Z"
    },
    "id": "X2ubU3A2c8tB",
    "outputId": "1c9d2251-1818-4467-9f74-ecd3731f8144"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "criterion = pspnet_loss(aux_weight=0.4)\n",
    "\n",
    "# create model, optimizer, lr_scheduler and pass to training function\n",
    "model = PSPNet(in_channels=3, num_classes=NUM_CLASSES, use_aux=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=MAX_LR)\n",
    "scheduler = OneCycleLR(optimizer, max_lr= MAX_LR, epochs = N_EPOCHS,steps_per_epoch = len(train_dataloader), \n",
    "                       pct_start=0.3, div_factor=10, anneal_strategy='cos')\n",
    "\n",
    "_ = train_validate_model(model, N_EPOCHS, MODEL_NAME, criterion, optimizer, \n",
    "                         device, train_dataloader, val_dataloader, meanIoU, 'meanIoU',\n",
    "                         lr_scheduler = scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC2oS6V3c8tD"
   },
   "source": [
    "# 4. Evaluate : Evaluate the model on Test Data and visualize results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:23:50.478312Z",
     "iopub.status.busy": "2022-06-26T09:23:50.477984Z",
     "iopub.status.idle": "2022-06-26T09:24:00.007559Z",
     "shell.execute_reply": "2022-06-26T09:24:00.006524Z",
     "shell.execute_reply.started": "2022-06-26T09:23:50.478278Z"
    },
    "id": "E3Jq4ac8c8tD"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{output_path}/{MODEL_NAME}.pt', map_location=device))\n",
    "_, test_metric = evaluate_model(model, test_dataloader, criterion, meanIoU, device)\n",
    "print(f\"\\nModel has {test_metric} mean IoU in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:24:00.010060Z",
     "iopub.status.busy": "2022-06-26T09:24:00.009350Z",
     "iopub.status.idle": "2022-06-26T09:24:00.023044Z",
     "shell.execute_reply": "2022-06-26T09:24:00.022050Z",
     "shell.execute_reply.started": "2022-06-26T09:24:00.010018Z"
    },
    "id": "IJtD39Sxc8tE"
   },
   "outputs": [],
   "source": [
    "def visualizePredictions(model : torch.nn.Module, dataSet : Dataset,  \n",
    "                         device :torch.device, numTestSamples : int):\n",
    "    \"\"\"Function visualizes predictions of input model on samples from\n",
    "    cityscapes dataset provided\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model whose output we're to visualize\n",
    "        dataSet (Dataset): dataset to take samples from\n",
    "        device (torch.device): compute device as in GPU, CPU etc\n",
    "        numTestSamples (int): number of samples to plot\n",
    "    \"\"\"\n",
    "    model.to(device=device)\n",
    "    model.eval()\n",
    "\n",
    "    # predictions on random samples\n",
    "    testSamples = np.random.choice(len(dataSet), numTestSamples).tolist()\n",
    "    _, axes = plt.subplots(numTestSamples, 3, figsize=(3*6, numTestSamples * 4))\n",
    "    \n",
    "    for i, sampleID in enumerate(testSamples):\n",
    "        inputImage, gt = dataSet[sampleID]\n",
    "\n",
    "        # input rgb image   \n",
    "        inputImage = inputImage.to(device)\n",
    "        landscape = inverse_transform(inputImage).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        axes[i, 0].imshow(landscape)\n",
    "        axes[i, 0].set_title(\"Landscape\")\n",
    "\n",
    "        # groundtruth label image\n",
    "        label_class = gt.cpu().detach().numpy()\n",
    "        axes[i, 1].imshow(train_id_to_color[label_class])\n",
    "        axes[i, 1].set_title(\"Groudtruth Label\")\n",
    "\n",
    "        # predicted label image\n",
    "        y_pred = torch.argmax(model(inputImage.unsqueeze(0)), dim=1).squeeze(0)\n",
    "        label_class_predicted = y_pred.cpu().detach().numpy()    \n",
    "        axes[i, 2].imshow(train_id_to_color[label_class_predicted])\n",
    "        axes[i, 2].set_title(\"Predicted Label\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:24:00.024909Z",
     "iopub.status.busy": "2022-06-26T09:24:00.024540Z",
     "iopub.status.idle": "2022-06-26T09:24:01.239096Z",
     "shell.execute_reply": "2022-06-26T09:24:01.238155Z",
     "shell.execute_reply.started": "2022-06-26T09:24:00.024872Z"
    },
    "id": "7-qBVW0Ec8tF"
   },
   "outputs": [],
   "source": [
    "visualizePredictions(model, test_set, device, numTestSamples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVs_u2PaoJa0"
   },
   "source": [
    "## Test on sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T09:24:01.241454Z",
     "iopub.status.busy": "2022-06-26T09:24:01.240697Z",
     "iopub.status.idle": "2022-06-26T09:24:05.143641Z",
     "shell.execute_reply": "2022-06-26T09:24:05.142562Z",
     "shell.execute_reply.started": "2022-06-26T09:24:01.241413Z"
    },
    "id": "dEnKl73NoGvp"
   },
   "outputs": [],
   "source": [
    "input_video_path = f'{dataset_path}/bdd100k_test_{targetWidth}_{targetHeight}.avi'\n",
    "output_video_path = f'{output_path}/{MODEL_NAME}_output_{targetWidth}_{targetHeight}.avi'\n",
    "\n",
    "# handles for input output videos\n",
    "input_handle = cv2.VideoCapture(input_video_path)\n",
    "output_handle = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'DIVX'), 5, (targetWidth, targetHeight))\n",
    "\n",
    "# create progress bar\n",
    "num_frames = int(input_handle.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total = num_frames, position=0, leave=True)\n",
    "\n",
    "while(input_handle.isOpened()):\n",
    "    ret, frame = input_handle.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # create torch tensor to give as input to model\n",
    "        pt_image = preprocess(frame)\n",
    "        pt_image = pt_image.to(device)\n",
    "\n",
    "        # get model prediction and convert to corresponding color\n",
    "        y_pred = torch.argmax(model(pt_image.unsqueeze(0)), dim=1).squeeze(0)\n",
    "        predicted_labels = y_pred.cpu().detach().numpy()\n",
    "        cm_labels = (train_id_to_color[predicted_labels]).astype(np.uint8)\n",
    "\n",
    "        # overlay prediction over input frame\n",
    "        overlay_image = cv2.addWeighted(frame, 1, cm_labels, 0.25, 0)\n",
    "        overlay_image = cv2.cvtColor(overlay_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # write output result and update progress\n",
    "        output_handle.write(overlay_image)\n",
    "        pbar.update(1)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "output_handle.release()\n",
    "input_handle.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
