{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924eb9a8",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27b7d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jayaraman/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2661f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/deeplab1.png\", \"deeplab1.png\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5aea83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)['out'][0]\n",
    "output_predictions = output.argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce72e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22d45ba8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a color pallette, selecting a color for each class\n",
    "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "# plot the semantic segmentation predictions of 21 classes in each color\n",
    "r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_image.size)\n",
    "r.putpalette(colors)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94c520a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6b643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67622974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12a79e1b",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b60a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProjectRootPath() -> str:\n",
    "    projectRootPath  = os.path.dirname(sys.path[0])\n",
    "    return projectRootPath\n",
    "\n",
    "projectRootPath = getProjectRootPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093dbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(model : nn.Module, sampleInput : torch.Tensor, outputPath : str):\n",
    "    model.eval();\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                  sampleInput,                         # model input (or a tuple for multiple inputs)\n",
    "                  outputPath,   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['Model Input'],   # the model's input names\n",
    "                  output_names = ['Model Output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfa52e",
   "metadata": {},
   "source": [
    "## File constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34f63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saanple tensor for model input\n",
    "sampleInput = torch.Tensor(1, 3, 224, 224)\n",
    "\n",
    "# file path constants\n",
    "dataFolder = os.path.join(projectRootPath, *['data'])\n",
    "modelOutputPath = os.path.join(dataFolder, *['FCN_out.onnx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b509c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d607792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62736e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\torch\\onnx\\utils.py:1294: UserWarning: Provided key input for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n",
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\torch\\onnx\\utils.py:1294: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n",
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\torch\\onnx\\symbolic_helper.py:382: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.\n",
      "ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n",
      "We recommend using opset 11 and above for models using this operator.\n",
      "  \"\" + str(_export_onnx_opset_version) + \". \"\n"
     ]
    }
   ],
   "source": [
    "exportModel(model, sampleInput, outputPath=modelOutputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482016e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "for name,_ in model.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21af7e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCNHead(\n",
       "  (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a563c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "backboneOutput = model.backbone(sampleInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "279f73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportModel(model.classifier, backboneOutput['out'], os.path.join(dataFolder, *['FCNHead.onnx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020ef9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(imgseg)",
   "language": "python",
   "name": "imgseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
