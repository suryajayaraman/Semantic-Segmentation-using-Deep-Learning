{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkfoFeGlYxHY",
    "papermill": {
     "duration": 0.010624,
     "end_time": "2022-06-26T08:49:42.237976",
     "exception": false,
     "start_time": "2022-06-26T08:49:42.227352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Welcome to the `deeplabv3+` Workshop!\n",
    "In this workshop, we'll learn the concept of how to use deeplabv3+ model (involving Atrous convolutions, Atrous Spatial Pyramid Pooling, Decoder) for Semantic Segmentation using Pytorch. We'll do the following tasks:\n",
    "\n",
    "- Dataset : Download and use BDD100k dataset\n",
    "- Network : Define deeplabv3+ model using resnet50, Atrous convolutions, ASPP modules, Decoder\n",
    "- Training : Train and validate model on the custom dataset\n",
    "- Evaluate : Evaluate the model on Test Data and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:31:50.886284Z",
     "iopub.status.busy": "2022-07-01T12:31:50.885908Z",
     "iopub.status.idle": "2022-07-01T12:32:16.175032Z",
     "shell.execute_reply": "2022-07-01T12:32:16.174008Z",
     "shell.execute_reply.started": "2022-07-01T12:31:50.886200Z"
    },
    "id": "-njz3v-jGxsi",
    "outputId": "77838d12-01f5-4ab1-d1d8-8bbe08bf2cc1",
    "papermill": {
     "duration": 30.082697,
     "end_time": "2022-06-26T08:50:12.330123",
     "exception": false,
     "start_time": "2022-06-26T08:49:42.247426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except:\n",
    "    !pip install segmentation-models-pytorch\n",
    "    import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKDStTzOQ_3R",
    "papermill": {
     "duration": 0.011439,
     "end_time": "2022-06-26T08:50:12.35461",
     "exception": false,
     "start_time": "2022-06-26T08:50:12.343171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:16.177629Z",
     "iopub.status.busy": "2022-07-01T12:32:16.176921Z",
     "iopub.status.idle": "2022-07-01T12:32:16.337785Z",
     "shell.execute_reply": "2022-07-01T12:32:16.336684Z",
     "shell.execute_reply.started": "2022-07-01T12:32:16.177589Z"
    },
    "id": "-73t7omkQ-y7",
    "papermill": {
     "duration": 0.194583,
     "end_time": "2022-06-26T08:50:12.561377",
     "exception": false,
     "start_time": "2022-06-26T08:50:12.366794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# DL library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# libraries for loading image, plotting \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G6V9TIjsZB7",
    "papermill": {
     "duration": 0.011813,
     "end_time": "2022-06-26T08:50:12.585464",
     "exception": false,
     "start_time": "2022-06-26T08:50:12.573651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Dataset : Download and use BDD100k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:16.339851Z",
     "iopub.status.busy": "2022-07-01T12:32:16.339484Z",
     "iopub.status.idle": "2022-07-01T12:32:16.345210Z",
     "shell.execute_reply": "2022-07-01T12:32:16.344346Z",
     "shell.execute_reply.started": "2022-07-01T12:32:16.339815Z"
    },
    "papermill": {
     "duration": 0.024334,
     "end_time": "2022-06-26T08:50:12.62209",
     "exception": false,
     "start_time": "2022-06-26T08:50:12.597756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENVIRONMENT = 'kaggle'\n",
    "\n",
    "if ENVIRONMENT == 'kaggle':\n",
    "    dataset_path = '../input/image-segmentation'\n",
    "    output_path = '.'\n",
    "    \n",
    "elif ENVIRONMENT == 'colab':\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    os.chdir(\"/content/drive/My Drive/thinkAutonomous/image_segmentation\")\n",
    "    dataset_path = 'dataset'\n",
    "    output_path = 'dataset'\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(\"Env can be kaggle or colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:16.349352Z",
     "iopub.status.busy": "2022-07-01T12:32:16.348608Z",
     "iopub.status.idle": "2022-07-01T12:32:16.358094Z",
     "shell.execute_reply": "2022-07-01T12:32:16.357022Z",
     "shell.execute_reply.started": "2022-07-01T12:32:16.349314Z"
    },
    "id": "adLoblQrpzzy",
    "outputId": "695af3d8-f020-4f37-9734-dcf9f0163229",
    "papermill": {
     "duration": 0.021882,
     "end_time": "2022-06-26T08:50:12.655679",
     "exception": false,
     "start_time": "2022-06-26T08:50:12.633797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targetWidth = 320\n",
    "targetHeight = 180\n",
    "\n",
    "# batch size for data loaders\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE  = 8\n",
    "\n",
    "# Hyperparameters\n",
    "N_EPOCHS = 10\n",
    "NUM_CLASSES = 3\n",
    "MAX_LR = 3e-4\n",
    "MODEL_NAME = 'deeplabv3_plus_resnet50_os8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:16.359912Z",
     "iopub.status.busy": "2022-07-01T12:32:16.359490Z",
     "iopub.status.idle": "2022-07-01T12:32:25.897123Z",
     "shell.execute_reply": "2022-07-01T12:32:25.896112Z",
     "shell.execute_reply.started": "2022-07-01T12:32:16.359872Z"
    },
    "papermill": {
     "duration": 7.356877,
     "end_time": "2022-06-26T08:50:20.024259",
     "exception": false,
     "start_time": "2022-06-26T08:50:12.667382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = np.load(f'{dataset_path}/image_{targetHeight}_{targetWidth}.npy')\n",
    "labels = np.load(f'{dataset_path}/label_{targetHeight}_{targetWidth}.npy')\n",
    "print(f\"RGB images shape = {images.shape}, Label images shape = {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmFiD3i-0Crd",
    "papermill": {
     "duration": 0.011764,
     "end_time": "2022-06-26T08:50:20.048453",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.036689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Torch Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:25.899160Z",
     "iopub.status.busy": "2022-07-01T12:32:25.898765Z",
     "iopub.status.idle": "2022-07-01T12:32:25.907068Z",
     "shell.execute_reply": "2022-07-01T12:32:25.905630Z",
     "shell.execute_reply.started": "2022-07-01T12:32:25.899120Z"
    },
    "id": "ySpXTOvpmPk8",
    "papermill": {
     "duration": 0.026094,
     "end_time": "2022-06-26T08:50:20.086444",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.06035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BDD100k_dataset(Dataset):\n",
    "    def __init__(self, images, labels, tf=None):\n",
    "        \"\"\"Dataset class for BDD100k_dataset drivable / segmentation data \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.tf = tf\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # read source image and convert to RGB, apply transform\n",
    "        rgb_image = self.images[index]\n",
    "        if self.tf is not None:\n",
    "            rgb_image = self.tf(rgb_image)\n",
    "\n",
    "        # read label image and convert to torch tensor\n",
    "        label_image  = torch.from_numpy(self.labels[index]).long()\n",
    "        return rgb_image, label_image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:25.909567Z",
     "iopub.status.busy": "2022-07-01T12:32:25.909126Z",
     "iopub.status.idle": "2022-07-01T12:32:25.922262Z",
     "shell.execute_reply": "2022-07-01T12:32:25.921373Z",
     "shell.execute_reply.started": "2022-07-01T12:32:25.909529Z"
    },
    "id": "r6XW6HajnzPq",
    "papermill": {
     "duration": 0.022318,
     "end_time": "2022-06-26T08:50:20.120884",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.098566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to torch tensor and normalize images using Imagenet values\n",
    "preprocess = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.56, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data = BDD100k_dataset(images, labels, tf=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB9JLxjfoENJ",
    "papermill": {
     "duration": 0.012113,
     "end_time": "2022-06-26T08:50:20.144725",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.132612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Splitting Training data into train and validation sets, creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:25.924153Z",
     "iopub.status.busy": "2022-07-01T12:32:25.923770Z",
     "iopub.status.idle": "2022-07-01T12:32:25.935756Z",
     "shell.execute_reply": "2022-07-01T12:32:25.934820Z",
     "shell.execute_reply.started": "2022-07-01T12:32:25.924118Z"
    },
    "id": "KKXj9c2qoC40",
    "papermill": {
     "duration": 0.026449,
     "end_time": "2022-06-26T08:50:20.182948",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.156499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split train data into train, validation and test sets\n",
    "total_count = len(data)\n",
    "train_count = int(0.7 * total_count) \n",
    "valid_count = int(0.2 * total_count)\n",
    "test_count = total_count - train_count - valid_count\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(data, \n",
    "            (train_count, valid_count, test_count), generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE,drop_last=True)\n",
    "val_dataloader   = DataLoader(val_set, batch_size=TEST_BATCH_SIZE)\n",
    "test_dataloader  = DataLoader(test_set, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku1BYOyXosMD",
    "papermill": {
     "duration": 0.01174,
     "end_time": "2022-06-26T08:50:20.20643",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.19469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's verify size of images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:25.937616Z",
     "iopub.status.busy": "2022-07-01T12:32:25.937116Z",
     "iopub.status.idle": "2022-07-01T12:32:25.953981Z",
     "shell.execute_reply": "2022-07-01T12:32:25.953033Z",
     "shell.execute_reply.started": "2022-07-01T12:32:25.937583Z"
    },
    "id": "yWrMEcQQota2",
    "outputId": "088865c6-546f-4b68-a0b0-4a35a99d03f9",
    "papermill": {
     "duration": 0.030787,
     "end_time": "2022-06-26T08:50:20.24967",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.218883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_image, sample_label = train_set[0]\n",
    "print(f\"There are {len(train_set)} train images, {len(val_set)} validation images, {len(test_set)} test Images\")\n",
    "print(f\"Input shape = {sample_image.shape}, output label shape = {sample_label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhMFn7YWprGr",
    "papermill": {
     "duration": 0.011704,
     "end_time": "2022-06-26T08:50:20.273389",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.261685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Show Sample images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:25.958195Z",
     "iopub.status.busy": "2022-07-01T12:32:25.957940Z",
     "iopub.status.idle": "2022-07-01T12:32:25.964997Z",
     "shell.execute_reply": "2022-07-01T12:32:25.963968Z",
     "shell.execute_reply.started": "2022-07-01T12:32:25.958166Z"
    },
    "id": "jOQpj7kfq_tM",
    "papermill": {
     "duration": 0.024433,
     "end_time": "2022-06-26T08:50:20.30992",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.285487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reference : https://github.com/bdd100k/bdd100k/blob/master/bdd100k/label/label.py\n",
    "from collections import namedtuple\n",
    "Label = namedtuple( \"Label\", [ \"name\", \"train_id\", \"color\"])\n",
    "drivables = [ \n",
    "             Label(\"direct\", 0, (219, 94, 86)),        # red\n",
    "             Label(\"alternative\", 1, (86, 211, 219)),  # cyan\n",
    "             Label(\"background\", 2, (0, 0, 0)),        # black          \n",
    "            ]\n",
    "train_id_to_color = [c.color for c in drivables if (c.train_id != -1 and c.train_id != 255)]\n",
    "train_id_to_color = np.array(train_id_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:25.967004Z",
     "iopub.status.busy": "2022-07-01T12:32:25.966287Z",
     "iopub.status.idle": "2022-07-01T12:32:26.299616Z",
     "shell.execute_reply": "2022-07-01T12:32:26.298636Z",
     "shell.execute_reply.started": "2022-07-01T12:32:25.966965Z"
    },
    "id": "UneBdP1LvZQr",
    "outputId": "cf00c661-2725-4604-bc6c-ce4a72f11139",
    "papermill": {
     "duration": 0.391109,
     "end_time": "2022-06-26T08:50:20.71382",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.322711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# when using torch datasets we defined earlier, the output image\n",
    "# is normalized. So we're defining an inverse transformation to \n",
    "# transform to normal RGB format\n",
    "inverse_transform = transforms.Compose([\n",
    "        transforms.Normalize((-0.485/0.229, -0.456/0.224, -0.406/0.225), (1/0.229, 1/0.224, 1/0.225))\n",
    "    ])\n",
    "\n",
    "rgb_image, label = train_set[random.randint(0, len(train_set))]\n",
    "rgb_image = inverse_transform(rgb_image).permute(1, 2, 0).cpu().detach().numpy()\n",
    "label = label.cpu().detach().numpy()\n",
    "\n",
    "# plot sample image\n",
    "fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "axes[0].imshow(rgb_image);\n",
    "axes[0].set_title(\"Image\");\n",
    "axes[0].axis('off');\n",
    "axes[1].imshow(train_id_to_color[label]);\n",
    "axes[1].set_title(\"Label\");\n",
    "axes[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbOYP8UHc8s3",
    "papermill": {
     "duration": 0.016732,
     "end_time": "2022-06-26T08:50:20.748023",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.731291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Network : Define deeplabv3+ model using resnet50, Atrous convolutions, ASPP modules, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.302749Z",
     "iopub.status.busy": "2022-07-01T12:32:26.300913Z",
     "iopub.status.idle": "2022-07-01T12:32:26.310287Z",
     "shell.execute_reply": "2022-07-01T12:32:26.309185Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.302711Z"
    }
   },
   "outputs": [],
   "source": [
    "class aspp_conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation_rate):\n",
    "        super(aspp_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, dilation=dilation_rate, padding=dilation_rate, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.312787Z",
     "iopub.status.busy": "2022-07-01T12:32:26.312067Z",
     "iopub.status.idle": "2022-07-01T12:32:26.321952Z",
     "shell.execute_reply": "2022-07-01T12:32:26.321032Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.312753Z"
    }
   },
   "outputs": [],
   "source": [
    "class aspp_pool(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(aspp_pool, self).__init__()\n",
    "        self.pooling_module = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[-2:]\n",
    "        x = self.pooling_module(x)\n",
    "        return F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.323600Z",
     "iopub.status.busy": "2022-07-01T12:32:26.323179Z",
     "iopub.status.idle": "2022-07-01T12:32:26.337504Z",
     "shell.execute_reply": "2022-07-01T12:32:26.336481Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.323566Z"
    }
   },
   "outputs": [],
   "source": [
    "class atrous_spatial_pyramid_pooling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation_rates):\n",
    "        super(atrous_spatial_pyramid_pooling, self).__init__()\n",
    "\n",
    "        layers = nn.ModuleList([])\n",
    "        \n",
    "        # skip-connection, match the output channels\n",
    "        # using 1x1 convolutions\n",
    "        layers.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "        \n",
    "        # spatial pyramid pooling wiht atrous convolutions\n",
    "        for rate in dilation_rates:\n",
    "            layers.append(aspp_conv(in_channels, out_channels, rate))\n",
    "            \n",
    "        # image pooling layer\n",
    "        layers.append(aspp_pool(in_channels, out_channels))\n",
    "        \n",
    "        # create Pytorch module list\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        # 1x1 convolution to project concatenated output\n",
    "        # to desired number of channels\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(len(layers) * out_channels, out_channels, kernel_size=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_outputs = []\n",
    "        for mod in self.layers:\n",
    "            mod_output = mod(x)\n",
    "            conv_outputs.append(mod_output)\n",
    "        \n",
    "        # concatenate output and reduce num_channels\n",
    "        output = self.project(torch.cat(conv_outputs, dim=1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.340663Z",
     "iopub.status.busy": "2022-07-01T12:32:26.339689Z",
     "iopub.status.idle": "2022-07-01T12:32:26.352468Z",
     "shell.execute_reply": "2022-07-01T12:32:26.351520Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.340612Z"
    }
   },
   "outputs": [],
   "source": [
    "class deeplabv3_decoder(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(deeplabv3_decoder, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # resnet low level features contain 256 channels\n",
    "        self.low_level_project = nn.Sequential(\n",
    "            nn.Conv2d(256, 48, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        # classifier head\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Conv2d(304, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(),            \n",
    "            nn.Conv2d(256, self.num_classes, kernel_size=1))\n",
    "                     \n",
    "        \n",
    "    def forward(self, x, low_level_feat):\n",
    "        # projected_low_level_feat = (48, h//4, w//4)\n",
    "        low_level_feat = self.low_level_project(low_level_feat)\n",
    "\n",
    "        # x = (256, h//4, w//4)\n",
    "        x = F.interpolate(x, size=low_level_feat.size()[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # x = (256 + 48, h//4, w//4)\n",
    "        x = torch.cat((x, low_level_feat), dim=1)\n",
    "        \n",
    "        # x = (num_classes, h//4, w//4)\n",
    "        x = self.cls(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.354241Z",
     "iopub.status.busy": "2022-07-01T12:32:26.353880Z",
     "iopub.status.idle": "2022-07-01T12:32:26.369647Z",
     "shell.execute_reply": "2022-07-01T12:32:26.368481Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.354205Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "class deeplabv3_plus(nn.Module):\n",
    "    def __init__(self, in_channels, output_stride, num_classes):\n",
    "        super(deeplabv3_plus, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.output_stride = output_stride\n",
    "        \n",
    "        if(output_stride == 16):\n",
    "            dilation_rates = [6, 12, 18]\n",
    "            replace_stride_with_dilation = [False, False, True]\n",
    "            \n",
    "        elif(output_stride == 8):\n",
    "            dilation_rates = [12, 24, 36]\n",
    "            replace_stride_with_dilation=[False, True, True]\n",
    "                \n",
    "        # backbone layers    \n",
    "        backbone = resnet50(pretrained=True, replace_stride_with_dilation = replace_stride_with_dilation)        \n",
    "        self.initial = nn.Sequential(*list(backbone.children())[:4])\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "        \n",
    "        # ASPP modules\n",
    "        aspp_out_channels = 256\n",
    "        aspp_in_channels = int(backbone.fc.in_features)        \n",
    "        self.aspp_module = atrous_spatial_pyramid_pooling(aspp_in_channels, \n",
    "                       out_channels=aspp_out_channels, dilation_rates=dilation_rates)\n",
    "        \n",
    "        # Decoder module\n",
    "        self.decoder = deeplabv3_decoder(self.num_classes)\n",
    "                      \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[-2:]\n",
    "        \n",
    "        # Pass input through Backbone layers\n",
    "        x = self.initial(x)\n",
    "        low_level_feat = self.layer1(x)\n",
    "        x = self.layer2(low_level_feat)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "                        \n",
    "        # ASPP and classifier layers\n",
    "        aspp_output = self.aspp_module(x)\n",
    "        decoder_output = self.decoder(aspp_output, low_level_feat)\n",
    "        return F.interpolate(decoder_output, size=input_size, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeI63CaFc8s6",
    "papermill": {
     "duration": 0.014939,
     "end_time": "2022-06-26T08:50:20.843048",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.828109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Training : Train and validate model on the custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hBQ5Xmuc8s7",
    "papermill": {
     "duration": 0.015023,
     "end_time": "2022-06-26T08:50:20.87336",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.858337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Before we train our model, we'll define some helper functions to calculate metric, plot training results etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2saoCUQc8s8",
    "papermill": {
     "duration": 0.014984,
     "end_time": "2022-06-26T08:50:20.903726",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.888742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric - meanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.373076Z",
     "iopub.status.busy": "2022-07-01T12:32:26.372451Z",
     "iopub.status.idle": "2022-07-01T12:32:26.384461Z",
     "shell.execute_reply": "2022-07-01T12:32:26.383644Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.373040Z"
    },
    "id": "MRyngm4nc8s8",
    "papermill": {
     "duration": 0.031897,
     "end_time": "2022-06-26T08:50:20.950986",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.919089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class meanIoU:\n",
    "    \"\"\" Class to find the mean IoU using confusion matrix approach \"\"\"    \n",
    "    def __init__(self, num_classes):\n",
    "        self.iou_metric = 0.0\n",
    "        self.num_classes = num_classes\n",
    "        # placeholder for confusion matrix on entire dataset\n",
    "        self.confusion_matrix = np.zeros((self.num_classes, self.num_classes))\n",
    "\n",
    "    def update(self, y_preds, labels):\n",
    "        \"\"\" Function finds the IoU for the input batch\n",
    "        and add batch metrics to overall metrics \"\"\"\n",
    "        predicted_labels = torch.argmax(y_preds, dim=1)\n",
    "        batch_confusion_matrix = self._fast_hist(labels.numpy().flatten(), predicted_labels.numpy().flatten())\n",
    "        self.confusion_matrix += batch_confusion_matrix\n",
    "    \n",
    "    def _fast_hist(self, label_true, label_pred):\n",
    "        \"\"\" Function to calculate confusion matrix on single batch \"\"\"\n",
    "        mask = (label_true >= 0) & (label_true < self.num_classes)\n",
    "        hist = np.bincount(\n",
    "            self.num_classes * label_true[mask].astype(int) + label_pred[mask],\n",
    "            minlength=self.num_classes ** 2,\n",
    "        ).reshape(self.num_classes, self.num_classes)\n",
    "        return hist\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\" Computes overall meanIoU metric from confusion matrix data \"\"\" \n",
    "        hist = self.confusion_matrix\n",
    "        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "        mean_iu = np.nanmean(iu)\n",
    "        return mean_iu\n",
    "\n",
    "    def reset(self):\n",
    "        self.iou_metric = 0.0\n",
    "        self.confusion_matrix = np.zeros((self.num_classes, self.num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZBAn9xXc8s9",
    "papermill": {
     "duration": 0.014709,
     "end_time": "2022-06-26T08:50:20.980681",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.965972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.388008Z",
     "iopub.status.busy": "2022-07-01T12:32:26.387744Z",
     "iopub.status.idle": "2022-07-01T12:32:26.398660Z",
     "shell.execute_reply": "2022-07-01T12:32:26.397595Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.387986Z"
    },
    "id": "2Ft6-lRuc8s-",
    "papermill": {
     "duration": 0.027626,
     "end_time": "2022-06-26T08:50:21.02371",
     "exception": false,
     "start_time": "2022-06-26T08:50:20.996084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_results(df, model_name):\n",
    "    fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "    ax1.set_ylabel('trainLoss', color='tab:red')\n",
    "    ax1.plot(df['epoch'].values, df['trainLoss'].values, color='tab:red')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('validationLoss', color='tab:blue')\n",
    "    ax2.plot(df['epoch'].values, df['validationLoss'].values, color='tab:blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    plt.suptitle(f'{model_name} Training, Validation Curves')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye0G3dMEc8s-",
    "papermill": {
     "duration": 0.01499,
     "end_time": "2022-06-26T08:50:21.053894",
     "exception": false,
     "start_time": "2022-06-26T08:50:21.038904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.400713Z",
     "iopub.status.busy": "2022-07-01T12:32:26.400157Z",
     "iopub.status.idle": "2022-07-01T12:32:26.412695Z",
     "shell.execute_reply": "2022-07-01T12:32:26.411797Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.400668Z"
    },
    "id": "rq5tJoYXc8s_",
    "papermill": {
     "duration": 0.028779,
     "end_time": "2022-06-26T08:50:21.098007",
     "exception": false,
     "start_time": "2022-06-26T08:50:21.069228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, metric_class, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric_object = metric_class(NUM_CLASSES)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, total=len(dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)                \n",
    "            y_preds = model(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(y_preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # update batch metric information            \n",
    "            metric_object.update(y_preds.cpu().detach(), labels.cpu().detach())\n",
    "\n",
    "    evaluation_loss = total_loss / len(dataloader)\n",
    "    evaluation_metric = metric_object.compute()\n",
    "    return evaluation_loss, evaluation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.416296Z",
     "iopub.status.busy": "2022-07-01T12:32:26.416000Z",
     "iopub.status.idle": "2022-07-01T12:32:26.428686Z",
     "shell.execute_reply": "2022-07-01T12:32:26.427715Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.416272Z"
    },
    "id": "oSX6yKZQc8tA",
    "papermill": {
     "duration": 0.034135,
     "end_time": "2022-06-26T08:50:21.147099",
     "exception": false,
     "start_time": "2022-06-26T08:50:21.112964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_validate_model(model, num_epochs, model_name, criterion, optimizer, \n",
    "                         device, dataloader_train, dataloader_valid, \n",
    "                         metric_class, metric_name, lr_scheduler = None):\n",
    "    # initialize placeholders for running values\n",
    "    results = []    \n",
    "    min_val_loss = np.Inf\n",
    "    len_train_loader = len(dataloader_train)\n",
    "\n",
    "    # move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting {epoch + 1} epoch ...\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in tqdm(dataloader_train, total=len_train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "\n",
    "            # Forward pass\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            train_loss += loss.item()\n",
    "              \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # adjust learning rate\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step()\n",
    "            \n",
    "        # compute per batch losses, metric value\n",
    "        train_loss = train_loss / len(dataloader_train)\n",
    "        validation_loss, validation_metric = evaluate_model(\n",
    "                        model, dataloader_valid, criterion, metric_class, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, trainLoss:{train_loss:6.5f}, validationLoss:{validation_loss:6.5f}, {metric_name}:{validation_metric: 4.2f}')\n",
    "        \n",
    "        # store results\n",
    "        results.append({'epoch': epoch, \n",
    "                        'trainLoss': train_loss, \n",
    "                        'validationLoss': validation_loss, \n",
    "                        f'{metric_name}': validation_metric})\n",
    "        \n",
    "        # if validation loss has decreased, save model and reset variable\n",
    "        if validation_loss <= min_val_loss:\n",
    "            min_val_loss = validation_loss\n",
    "            torch.save(model.state_dict(), f\"{output_path}/{model_name}.pt\")\n",
    "\n",
    "    # plot results\n",
    "    results = pd.DataFrame(results)\n",
    "    plot_training_results(results, model_name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCnjwooT0Rde",
    "papermill": {
     "duration": 0.01544,
     "end_time": "2022-06-26T08:50:21.177545",
     "exception": false,
     "start_time": "2022-06-26T08:50:21.162105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:32:26.430944Z",
     "iopub.status.busy": "2022-07-01T12:32:26.430518Z",
     "iopub.status.idle": "2022-07-01T12:55:26.277301Z",
     "shell.execute_reply": "2022-07-01T12:55:26.276366Z",
     "shell.execute_reply.started": "2022-07-01T12:32:26.430905Z"
    },
    "id": "X2ubU3A2c8tB",
    "outputId": "1c9d2251-1818-4467-9f74-ecd3731f8144",
    "papermill": {
     "duration": 1209.465044,
     "end_time": "2022-06-26T09:10:30.657832",
     "exception": false,
     "start_time": "2022-06-26T08:50:21.192788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# reference : https://smp.readthedocs.io/en/latest/losses.html\n",
    "criterion = smp.losses.DiceLoss('multiclass', classes=[0,1,2], log_loss = True, smooth=1.0)\n",
    "\n",
    "# create model, optimizer, lr_scheduler and pass to training function\n",
    "model = deeplabv3_plus(in_channels=3, output_stride=8, num_classes=NUM_CLASSES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=MAX_LR)\n",
    "scheduler = OneCycleLR(optimizer, max_lr= MAX_LR, epochs = N_EPOCHS,steps_per_epoch = len(train_dataloader), \n",
    "                       pct_start=0.3, div_factor=10, anneal_strategy='cos')\n",
    "\n",
    "_ = train_validate_model(model, N_EPOCHS, MODEL_NAME, criterion, optimizer, \n",
    "                         device, train_dataloader, val_dataloader, meanIoU, 'meanIoU',\n",
    "                         lr_scheduler = scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC2oS6V3c8tD",
    "papermill": {
     "duration": 0.293933,
     "end_time": "2022-06-26T09:10:31.333269",
     "exception": false,
     "start_time": "2022-06-26T09:10:31.039336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Evaluate : Evaluate the model on Test Data and visualize results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:55:26.279284Z",
     "iopub.status.busy": "2022-07-01T12:55:26.278948Z",
     "iopub.status.idle": "2022-07-01T12:55:37.097026Z",
     "shell.execute_reply": "2022-07-01T12:55:37.095018Z",
     "shell.execute_reply.started": "2022-07-01T12:55:26.279249Z"
    },
    "id": "E3Jq4ac8c8tD",
    "papermill": {
     "duration": 10.553859,
     "end_time": "2022-06-26T09:10:42.184389",
     "exception": false,
     "start_time": "2022-06-26T09:10:31.63053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{output_path}/{MODEL_NAME}.pt', map_location=device))\n",
    "_, test_metric = evaluate_model(model, test_dataloader, criterion, meanIoU, device)\n",
    "print(f\"\\nModel has {test_metric} mean IoU in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:55:37.099098Z",
     "iopub.status.busy": "2022-07-01T12:55:37.098337Z",
     "iopub.status.idle": "2022-07-01T12:55:37.111039Z",
     "shell.execute_reply": "2022-07-01T12:55:37.110017Z",
     "shell.execute_reply.started": "2022-07-01T12:55:37.099059Z"
    },
    "id": "IJtD39Sxc8tE",
    "papermill": {
     "duration": 0.315446,
     "end_time": "2022-06-26T09:10:42.799701",
     "exception": false,
     "start_time": "2022-06-26T09:10:42.484255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualizePredictions(model : torch.nn.Module, dataSet : Dataset,  \n",
    "                         device :torch.device, numTestSamples : int):\n",
    "    \"\"\"Function visualizes predictions of input model on samples from\n",
    "    cityscapes dataset provided\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model whose output we're to visualize\n",
    "        dataSet (Dataset): dataset to take samples from\n",
    "        device (torch.device): compute device as in GPU, CPU etc\n",
    "        numTestSamples (int): number of samples to plot\n",
    "    \"\"\"\n",
    "    model.to(device=device)\n",
    "    model.eval()\n",
    "\n",
    "    # predictions on random samples\n",
    "    testSamples = np.random.choice(len(dataSet), numTestSamples).tolist()\n",
    "    _, axes = plt.subplots(numTestSamples, 3, figsize=(3*6, numTestSamples * 4))\n",
    "    \n",
    "    for i, sampleID in enumerate(testSamples):\n",
    "        inputImage, gt = dataSet[sampleID]\n",
    "\n",
    "        # input rgb image   \n",
    "        inputImage = inputImage.to(device)\n",
    "        landscape = inverse_transform(inputImage).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        axes[i, 0].imshow(landscape)\n",
    "        axes[i, 0].set_title(\"Landscape\")\n",
    "\n",
    "        # groundtruth label image\n",
    "        label_class = gt.cpu().detach().numpy()\n",
    "        axes[i, 1].imshow(train_id_to_color[label_class])\n",
    "        axes[i, 1].set_title(\"Groudtruth Label\")\n",
    "\n",
    "        # predicted label image\n",
    "        y_pred = torch.argmax(model(inputImage.unsqueeze(0)), dim=1).squeeze(0)\n",
    "        label_class_predicted = y_pred.cpu().detach().numpy()    \n",
    "        axes[i, 2].imshow(train_id_to_color[label_class_predicted])\n",
    "        axes[i, 2].set_title(\"Predicted Label\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:55:37.113125Z",
     "iopub.status.busy": "2022-07-01T12:55:37.112198Z",
     "iopub.status.idle": "2022-07-01T12:55:38.107252Z",
     "shell.execute_reply": "2022-07-01T12:55:38.106185Z",
     "shell.execute_reply.started": "2022-07-01T12:55:37.113052Z"
    },
    "id": "7-qBVW0Ec8tF",
    "papermill": {
     "duration": 1.570233,
     "end_time": "2022-06-26T09:10:44.663769",
     "exception": false,
     "start_time": "2022-06-26T09:10:43.093536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualizePredictions(model, test_set, device, numTestSamples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVs_u2PaoJa0",
    "papermill": {
     "duration": 0.298323,
     "end_time": "2022-06-26T09:10:45.293839",
     "exception": false,
     "start_time": "2022-06-26T09:10:44.995516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test on sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:55:38.109272Z",
     "iopub.status.busy": "2022-07-01T12:55:38.108715Z",
     "iopub.status.idle": "2022-07-01T12:55:42.666300Z",
     "shell.execute_reply": "2022-07-01T12:55:42.665242Z",
     "shell.execute_reply.started": "2022-07-01T12:55:38.109234Z"
    },
    "id": "dEnKl73NoGvp",
    "papermill": {
     "duration": 5.021704,
     "end_time": "2022-06-26T09:10:50.616161",
     "exception": false,
     "start_time": "2022-06-26T09:10:45.594457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_video_path = f'{dataset_path}/bdd100k_test_{targetWidth}_{targetHeight}.avi'\n",
    "output_video_path = f'{output_path}/{MODEL_NAME}_output_{targetWidth}_{targetHeight}.avi'\n",
    "\n",
    "# handles for input output videos\n",
    "input_handle = cv2.VideoCapture(input_video_path)\n",
    "output_handle = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'DIVX'), 5, (targetWidth, targetHeight))\n",
    "\n",
    "# create progress bar\n",
    "num_frames = int(input_handle.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total = num_frames, position=0, leave=True)\n",
    "\n",
    "while(input_handle.isOpened()):\n",
    "    ret, frame = input_handle.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # create torch tensor to give as input to model\n",
    "        pt_image = preprocess(frame)\n",
    "        pt_image = pt_image.to(device)\n",
    "\n",
    "        # get model prediction and convert to corresponding color\n",
    "        y_pred = torch.argmax(model(pt_image.unsqueeze(0)), dim=1).squeeze(0)\n",
    "        predicted_labels = y_pred.cpu().detach().numpy()\n",
    "        cm_labels = (train_id_to_color[predicted_labels]).astype(np.uint8)\n",
    "\n",
    "        # overlay prediction over input frame\n",
    "        overlay_image = cv2.addWeighted(frame, 1, cm_labels, 0.25, 0)\n",
    "        overlay_image = cv2.cvtColor(overlay_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # write output result and update progress\n",
    "        output_handle.write(overlay_image)\n",
    "        pbar.update(1)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "output_handle.release()\n",
    "input_handle.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
