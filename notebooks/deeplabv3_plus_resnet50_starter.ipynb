{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f855d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# basic imports\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# DL library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09903d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aspp_conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation_rate):\n",
    "        super(aspp_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, dilation=dilation_rate, padding=dilation_rate, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e3702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aspp_pool(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(aspp_pool, self).__init__()\n",
    "        self.pooling_module = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[-2:]\n",
    "        x = self.pooling_module(x)\n",
    "        return F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42411db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atrous_spatial_pyramid_pooling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation_rates):\n",
    "        super(atrous_spatial_pyramid_pooling, self).__init__()\n",
    "\n",
    "        layers = nn.ModuleList([])\n",
    "        \n",
    "        # skip-connection, match the output channels\n",
    "        # using 1x1 convolutions\n",
    "        layers.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "        \n",
    "        # spatial pyramid pooling wiht atrous convolutions\n",
    "        for rate in dilation_rates:\n",
    "            layers.append(aspp_conv(in_channels, out_channels, rate))\n",
    "            \n",
    "        # image pooling layer\n",
    "        layers.append(aspp_pool(in_channels, out_channels))\n",
    "        \n",
    "        # create Pytorch module list\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        # 1x1 convolution to project concatenated output\n",
    "        # to desired number of channels\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(len(layers) * out_channels, out_channels, kernel_size=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_outputs = []\n",
    "        for mod in self.layers:\n",
    "            mod_output = mod(x)\n",
    "            conv_outputs.append(mod_output)\n",
    "        \n",
    "        # concatenate output and reduce num_channels\n",
    "        output = self.project(torch.cat(conv_outputs, dim=1))\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a548ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplabv3_decoder(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(deeplabv3_decoder, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # resnet low level features contain 256 channels\n",
    "        self.low_level_project = nn.Sequential(\n",
    "            nn.Conv2d(256, 48, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        # classifier head\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Conv2d(304, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(),            \n",
    "            nn.Conv2d(256, self.num_classes, kernel_size=1))\n",
    "                     \n",
    "        \n",
    "    def forward(self, low_level_feat, aspp_out):\n",
    "        # projected_low_level_feat = (48, h//4, w//4)\n",
    "        projected_low_level_feat = self.low_level_project(low_level_feat)\n",
    "\n",
    "        # x = (256, h//4, w//4)\n",
    "        x = F.interpolate(projected_low_level_feat, size=low_level_feat.size()[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # x = (256 + 48, h//4, w//4)\n",
    "        x = torch.cat((x, low_level_feat), dim=1)\n",
    "        \n",
    "        # x = (num_classes, h//4, w//4)\n",
    "        x = self.cls(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8362a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplabv3_plus(nn.Module):\n",
    "    def __init__(self, in_channels, output_stride, num_classes):\n",
    "        super(deeplabv3_plus, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.output_stride = output_stride\n",
    "        \n",
    "        if(output_stride == 16):\n",
    "            dilation_rates = [6, 12, 18]\n",
    "            replace_stride_with_dilation = [False, False, True]\n",
    "            \n",
    "        elif(output_stride == 8):\n",
    "            dilation_rates = [12, 24, 36]\n",
    "            replace_stride_with_dilation=[False, True, True]\n",
    "                \n",
    "        # backbone layers    \n",
    "        backbone = resnet50(pretrained=True, replace_stride_with_dilation = replace_stride_with_dilation)        \n",
    "        self.initial = nn.Sequential(*list(backbone.children())[:4])\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "        \n",
    "        # ASPP modules\n",
    "        aspp_out_channels = 256\n",
    "        aspp_in_channels = int(backbone.fc.in_features)        \n",
    "        self.aspp_module = atrous_spatial_pyramid_pooling(aspp_in_channels, \n",
    "                       out_channels=aspp_out_channels, dilation_rates=dilation_rates)\n",
    "        \n",
    "        # Decoder module\n",
    "        self.decoder = deeplabv3_decoder(self.num_classes)\n",
    "                      \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[-2:]\n",
    "        \n",
    "        # Pass input through Backbone layers\n",
    "        x = self.initial(x)\n",
    "        low_level_feat = self.layer1(x)\n",
    "        x = self.layer2(low_level_feat)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "                        \n",
    "        # ASPP and classifier layers\n",
    "        aspp_output = self.aspp_module(x)\n",
    "        decoder_output = self.decoder(low_level_feat, aspp_output)\n",
    "        return F.interpolate(decoder_output, size=input_size, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3fa097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 180, 320])\n"
     ]
    }
   ],
   "source": [
    "model = deeplabv3_plus(in_channels=3, output_stride=16, num_classes=3)\n",
    "test_input = torch.Tensor(2,3,180, 320)\n",
    "output = model(test_input)\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(imgseg)",
   "language": "python",
   "name": "imgseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
