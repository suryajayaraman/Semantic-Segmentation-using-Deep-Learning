{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924eb9a8",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27b7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a79e1b",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b60a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProjectRootPath() -> str:\n",
    "    projectRootPath  = os.path.dirname(sys.path[0])\n",
    "    return projectRootPath\n",
    "\n",
    "projectRootPath = getProjectRootPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093dbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(model : nn.Module, sampleInput : torch.Tensor, outputPath : str):\n",
    "    model.eval();\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                  sampleInput,                         # model input (or a tuple for multiple inputs)\n",
    "                  outputPath,   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['Model Input'],   # the model's input names\n",
    "                  output_names = ['Model Output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfa52e",
   "metadata": {},
   "source": [
    "## File constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34f63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saanple tensor for model input\n",
    "sampleInput = torch.Tensor(1, 3, 224, 224)\n",
    "\n",
    "# file path constants\n",
    "dataFolder = os.path.join(projectRootPath, *['data'])\n",
    "modelOutputPath = os.path.join(dataFolder, *['FCN_out.onnx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b509c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d607792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62736e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\torch\\onnx\\utils.py:1294: UserWarning: Provided key input for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n",
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\torch\\onnx\\utils.py:1294: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n",
      "D:\\surya\\miniconda37\\envs\\imgseg\\lib\\site-packages\\torch\\onnx\\symbolic_helper.py:382: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.\n",
      "ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n",
      "We recommend using opset 11 and above for models using this operator.\n",
      "  \"\" + str(_export_onnx_opset_version) + \". \"\n"
     ]
    }
   ],
   "source": [
    "exportModel(model, sampleInput, outputPath=modelOutputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482016e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "for name,_ in model.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21af7e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCNHead(\n",
       "  (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a563c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "backboneOutput = model.backbone(sampleInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "279f73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportModel(model.classifier, backboneOutput['out'], os.path.join(dataFolder, *['FCNHead.onnx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020ef9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(imgseg)",
   "language": "python",
   "name": "imgseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
